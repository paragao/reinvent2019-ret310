{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create higher-quality recommendations in your e-commerce platform  with Amazon Personalize\n",
    "\n",
    "This notebook is part of Amazon re:Invent 2019 Builder's Session \"RET310 -  Create higher-quality recommendations in your e-commerce platform\".\n",
    "\n",
    "In this notebook, you will be able to run & deploy on your AWS account all steps taken during the session. By the end of it, endpoints will be ready to be used to perform recommendations on your e-commerce application.\n",
    "\n",
    "More details about the Buider's Session at this link: https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=98681\n",
    "\n",
    "The dataset used on this exercise was created by Olist and made available on Kaggle platform. To download the latest version of this dataset, as also to check details about the data and their schemas, please check: https://www.kaggle.com/olistbr/brazilian-ecommerce \n",
    "\n",
    "#### Important Note\n",
    "\n",
    "As for all Machine Learning solutions, data preparation is a key step to achieve higher quality on the final solution. For the data preparation steps taken on this exercise, please check the notebook \"RET310 - Data preparation steps.ipynb\" also present on this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Section 1 - Preparation steps](#first-section)\n",
    "* [Section 2 - Data schemas creation steps](#second-section)\n",
    "* [Section 3 - Create dataset group and datasets](#third-section)\n",
    "* [Section 4 - Importing Olist data into the datasets](#forth-section)\n",
    "* [Section 5 - Creating Solutions and training new Solutions versions](#fifth-section)\n",
    "* [Section 6 - Deploying Personalize Campaigns with the trained Solutions](#sixth-section)\n",
    "* [Section 7 - Testing the deployed Campaigns using the Python SDK](#seventh-section)\n",
    "* [Section 8 - Clean Up steps](#eighth-section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 - Preparation steps <a class=\"anchor\" id=\"first-section\"></a>\n",
    "\n",
    "On this section you will perform the pre-requisites to deploy the Amazon Personalize solution. It includes importing Python modules, defining S3 bucket information and creating IAM roles with appropriate access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "personalize = boto3.client('personalize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the IAM Role to be used by Amazon Personalize will be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')\n",
    "path='/'\n",
    "role_name='ret310-personalize-role' # you may change this role name if needed\n",
    "description='IAM role with permissions to run the lab RET310'\n",
    "trust_policy={\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Sid\": \"\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"personalize.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam.create_role(\n",
    "        Path=path,\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "        Description=description,\n",
    "        MaxSessionDuration=3600\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "roleArn = response['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the IAM Role created, an IAM Policy is created and attached to the IAM Role, allowing the appropriate access to the required services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:GetObject\",\n",
    "                \"personalize:*\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = iam.create_policy(PolicyName='ret310-policy', PolicyDocument=json.dumps(policy))\n",
    "policyArn = response['Policy']['Arn']\n",
    "\n",
    "iam.attach_role_policy(RoleName=role_name, PolicyArn=policyArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 - Data schemas creation steps <a class=\"anchor\" id=\"second-section\"></a>\n",
    "\n",
    "At this point, the data stored on S3 will be accessed, as also the initial Amazon Personalize preparation will be done, including data schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'personalize-lcm'\n",
    "users_data = 'users-olist.csv'\n",
    "products_data = 'products-olist.csv'\n",
    "interactions_data = 'orderItems-olist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar bucket policy\n",
    "# corrigir as aspas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Amazon Personalize schemas are created, based on Apache Avro standard. For more details, check: https://docs.aws.amazon.com/personalize/latest/dg/how-it-works-dataset-schema.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Users\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ZipCode\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"State\",\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "products_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Items\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"CATEGORY\",\n",
    "            \"type\": \"string\",\n",
    "            \"categorical\": True\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Timestamp\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Avro schemas defined, the schemas will be created for Users, Products and Interactions data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_users_schema_response = personalize.create_schema(name = 'ret310-users-schema', \n",
    "                                                         schema = json.dumps(users_schema))\n",
    "create_products_schema_response = personalize.create_schema(name = 'ret310-products-schema', \n",
    "                                                            schema = json.dumps(products_schema))\n",
    "create_interactions_schema_response = personalize.create_schema(name = 'ret310-interactions-schema', \n",
    "                                                                schema = json.dumps(interactions_schema))\n",
    "\n",
    "users_schema_arn = create_users_schema_response['schemaArn']\n",
    "products_schema_arn = create_products_schema_response['schemaArn']\n",
    "interactions_schema_arn = create_interactions_schema_response['schemaArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 - Create dataset group and datasets <a class=\"anchor\" id=\"third-section\"></a>\n",
    "\n",
    "First you will create the dataset group to be used on this exercise - it will be called \"ret310-dataset-group\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(name = 'ret310-dataset-group')\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(datasetGroupArn = dataset_group_arn)\n",
    "    status = describe_dataset_group_response['datasetGroup']['status']\n",
    "    print('DatasetGroup: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset group created, now you will create one dataset for each type of data: Users, Products and Interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset_type = 'USERS'\n",
    "create_dataset_response = personalize.create_dataset(name = 'ret310-users-dataset',\n",
    "                                                     datasetType = dataset_type,\n",
    "                                                     datasetGroupArn = dataset_group_arn,\n",
    "                                                     schemaArn = users_schema_arn)\n",
    "\n",
    "users_dataset_arn = create_dataset_response['datasetArn']\n",
    "\n",
    "dataset_type = 'ITEMS'\n",
    "create_dataset_response = personalize.create_dataset(name = 'ret310-items-dataset',\n",
    "                                                     datasetType = dataset_type,\n",
    "                                                     datasetGroupArn = dataset_group_arn,\n",
    "                                                     schemaArn = products_schema_arn)\n",
    "\n",
    "products_dataset_arn = create_dataset_response['datasetArn']\n",
    "\n",
    "dataset_type = 'INTERACTIONS'\n",
    "create_dataset_response = personalize.create_dataset(name = 'ret310-interactions-dataset',\n",
    "                                                     datasetType = dataset_type,\n",
    "                                                     datasetGroupArn = dataset_group_arn,\n",
    "                                                     schemaArn = interactions_schema_arn)\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4 - Importing Olist data into the datasets<a class=\"anchor\" id=\"forth-section\"></a>\n",
    "\n",
    "Now with all the datasets properly created, you will import the Olist data, stored on S3, into them.\n",
    "\n",
    "First you will import the Users data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_users_import_job_response = personalize.create_dataset_import_job(jobName = 'ret310-users-import-job',\n",
    "                                                                         datasetArn = users_dataset_arn,\n",
    "                                                                         roleArn = roleArn,\n",
    "                                                                         dataSource = {\n",
    "                                                                             'dataLocation': 's3://{}/{}'.format(bucket, users_data)\n",
    "                                                                         })\n",
    "\n",
    "dataset_import_job_arn = create_users_import_job_response['datasetImportJobArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    create_users_import_job_response = personalize.describe_dataset_import_job(datasetImportJobArn = dataset_import_job_arn)\n",
    "    status = create_users_import_job_response['datasetImportJob']['status']\n",
    "    print('DatasetImportJob: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you will import the Products data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_products_import_job_response = personalize.create_dataset_import_job(jobName = 'ret310-items-import-job',\n",
    "                                                                            datasetArn = products_dataset_arn,\n",
    "                                                                            roleArn = roleArn,\n",
    "                                                                            dataSource = {\n",
    "                                                                                'dataLocation': 's3://{}/{}'.format(bucket, products_data)\n",
    "                                                                            })\n",
    "\n",
    "dataset_import_job_arn = create_products_import_job_response['datasetImportJobArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    create_products_import_job_response = personalize.describe_dataset_import_job(datasetImportJobArn = dataset_import_job_arn)\n",
    "    status = create_products_import_job_response['datasetImportJob']['status']\n",
    "    print('DatasetImportJob: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you will finish the importing process, with the Interactions data import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_interactions_import_job_response = personalize.create_dataset_import_job(jobName = 'ret310-interactions-import-job',\n",
    "                                                                                datasetArn = interactions_dataset_arn,\n",
    "                                                                                roleArn = roleArn,\n",
    "                                                                                dataSource = {\n",
    "                                                                                    'dataLocation': 's3://{}/{}'.format(bucket, interactions_data)\n",
    "                                                                                })\n",
    "\n",
    "dataset_import_job_arn = create_interactions_import_job_response['datasetImportJobArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    create_interactions_import_job_response = personalize.describe_dataset_import_job(datasetImportJobArn = dataset_import_job_arn)\n",
    "    status = create_interactions_import_job_response['datasetImportJob']['status']\n",
    "    print('DatasetImportJob: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5 - Creating Solutions and training new Solutions versions<a class=\"anchor\" id=\"fifth-section\"></a>\n",
    "\n",
    "Now with all data ready, you will start creating and training Personalize Solutions with them - For this exercise, you will use Solutions based on the following recipes:\n",
    "- Popularity\n",
    "- Item-to-Item similarity (SIMS)\n",
    "- Personalized Ranking\n",
    "\n",
    "For more details about the Personalize predefined Recipes, check: https://docs.aws.amazon.com/personalize/latest/dg/working-with-predefined-recipes.html\n",
    "\n",
    "First you will list all the available recipes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_recipes_response = personalize.list_recipes()\n",
    "for recipe in list_recipes_response['recipes']:\n",
    "    print(recipe['name'], '-', recipe['recipeArn'], '-', recipe['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you will create the solutions to be used by this exercise into the \"ret310-dataset-group\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_arn = 'arn:aws:personalize:::recipe/aws-popularity-count'\n",
    "sims_arn = 'arn:aws:personalize:::recipe/aws-sims'\n",
    "ranking_arn = 'arn:aws:personalize:::recipe/aws-personalized-ranking'\n",
    "\n",
    "create_solution_response = personalize.create_solution(name = 'ret310-popularity-solution',\n",
    "                                                       datasetGroupArn = dataset_group_arn,\n",
    "                                                       recipeArn = popularity_arn)\n",
    "popularity_solution_arn = create_solution_response['solutionArn']\n",
    "\n",
    "create_solution_response = personalize.create_solution(name = 'ret310-sims-solution',\n",
    "                                                       datasetGroupArn = dataset_group_arn,\n",
    "                                                       recipeArn = sims_arn)\n",
    "sims_solution_arn = create_solution_response['solutionArn']\n",
    "\n",
    "create_solution_response = personalize.create_solution(name='ret310-sims-hpo-solution',\n",
    "                                                       recipeArn = sims_arn,\n",
    "                                                       datasetGroupArn = dataset_group_arn,\n",
    "                                                       performHPO=True,\n",
    "                                                       performAutoML=False,\n",
    "                                                       solutionConfig={\n",
    "                                                                        \"hpoConfig\": {\n",
    "                                                                            \"algorithmHyperParameterRanges\": {\n",
    "                                                                                \"categoricalHyperParameterRanges\": [],\n",
    "                                                                                \"continuousHyperParameterRanges\": [\n",
    "                                                                                    {\n",
    "                                                                                        \"name\": \"popularity_discount_factor\",\n",
    "                                                                                        \"minValue\": 0,\n",
    "                                                                                        \"maxValue\": 1\n",
    "                                                                                    }\n",
    "                                                                                ],\n",
    "                                                                                \"integerHyperParameterRanges\": [\n",
    "                                                                                    {\n",
    "                                                                                        \"name\": \"min_cointeraction_count\",\n",
    "                                                                                        \"minValue\": 0,\n",
    "                                                                                        \"maxValue\": 10\n",
    "                                                                                    }\n",
    "                                                                                ]\n",
    "                                                                            },\n",
    "                                                                            \"hpoResourceConfig\": {\n",
    "                                                                                \"maxNumberOfTrainingJobs\": \"20\",\n",
    "                                                                                \"maxParallelTrainingJobs\": \"5\"\n",
    "                                                                            }\n",
    "                                                                        },\n",
    "                                                                        \"featureTransformationParameters\": {\n",
    "                                                                            \"max_item_interaction_count_percentile\": \"0.9\",\n",
    "                                                                            \"max_user_history_length_percentile\": \"0.995\",\n",
    "                                                                            \"min_item_interaction_count_percentile\": \"0.01\",\n",
    "                                                                            \"min_user_history_length_percentile\": \"0.005\"\n",
    "                                                                        },\n",
    "                                                                        \"algorithmHyperParameters\": {\n",
    "                                                                            \"min_cointeraction_count\": \"3\",\n",
    "                                                                            \"popularity_discount_factor\": \"0.5\"\n",
    "                                                                        },\n",
    "                                                                    }\n",
    "                                                      )\n",
    "sims_hpo_solution_arn = create_solution_response['solutionArn']\n",
    "\n",
    "create_solution_response = personalize.create_solution(name = 'ret310-ranking-solution',\n",
    "                                                       datasetGroupArn = dataset_group_arn,\n",
    "                                                       recipeArn = ranking_arn)\n",
    "ranking_solution_arn = create_solution_response['solutionArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the solutions created, it is time to train them using the Olist dataset - First you will train the solution based on the Popularity - This one will be used just as a quality baseline, when comapring with SIMS based solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_solution_version_response = personalize.create_solution_version(solutionArn = popularity_solution_arn)\n",
    "popularity_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(solutionVersionArn = popularity_version_arn)\n",
    "    status = describe_solution_version_response['solutionVersion']['status']\n",
    "    print('SolutionVersion: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "\n",
    "get_solution_metrics_response = personalize.get_solution_metrics(solutionVersionArn = popularity_version_arn)\n",
    "print(json.dumps(get_solution_metrics_response['metrics'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will create the first solution using SIMS recipe - it will use the standard parameters while training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_solution_version_response = personalize.create_solution_version(solutionArn = sims_solution_arn)\n",
    "sims_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(solutionVersionArn = sims_version_arn)\n",
    "    status = describe_solution_version_response['solutionVersion']['status']\n",
    "    print('SolutionVersion: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "\n",
    "get_solution_metrics_response = personalize.get_solution_metrics(solutionVersionArn = sims_version_arn)\n",
    "print(json.dumps(get_solution_metrics_response['metrics'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will create another SIMS based solution, but this one will use the Hyperparameters Optimization (HPO) feature from Amazon Personalize. With HPO, Personalize will automatically tune the Solution and will provide you a final solution version using the best parameters from the training - based on the training metrics.\n",
    "\n",
    "For more details about Amazon Personalize HPO, please check: https://docs.aws.amazon.com/personalize/latest/dg/customizing-solution-config-hpo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_solution_version_response = personalize.create_solution_version(solutionArn = sims_hpo_solution_arn)\n",
    "sims_hpo_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(solutionVersionArn = sims_hpo_version_arn)\n",
    "    status = describe_solution_version_response['solutionVersion']['status']\n",
    "    print('SolutionVersion: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "\n",
    "get_solution_metrics_response = personalize.get_solution_metrics(solutionVersionArn = sims_hpo_version_arn)\n",
    "print(json.dumps(get_solution_metrics_response['metrics'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last Solution you will train is based on personalized ranking recipe. Instead of recommending products to a user as the last ones trained, it will prioritize a given list of products to a specific user. It is extremely useful to guide in which order is more adequate to present products to a given customer (like per example, when building a dynamic carousel on an e-commerce):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_solution_version_response = personalize.create_solution_version(solutionArn = ranking_solution_arn)\n",
    "ranking_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(solutionVersionArn = ranking_version_arn)\n",
    "    status = describe_solution_version_response['solutionVersion']['status']\n",
    "    print('SolutionVersion: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "\n",
    "get_solution_metrics_response = personalize.get_solution_metrics(solutionVersionArn = ranking_version_arn)\n",
    "print(json.dumps(get_solution_metrics_response['metrics'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6 - Deploying Personalize Campaigns with the trained Solutions<a class=\"anchor\" id=\"sixth-section\"></a>\n",
    "\n",
    "Deploying Campaigns is the way you can start doing actual recommendations with Personalize. With a Campaign, you will have an endpoint, backed by the Solution version you chose.\n",
    "\n",
    "For more details about Amazon Personalize Campaigns, please check: https://docs.aws.amazon.com/personalize/latest/dg/campaigns.html\n",
    "\n",
    "Here you will first create the campaign for the solution based on SIMS recipe -- here without the HPO optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_campaign_response = personalize.create_campaign(name = 'ret310-sims-campaign',\n",
    "                                                       solutionVersionArn = sims_version_arn,\n",
    "                                                       minProvisionedTPS = 1)\n",
    "\n",
    "sims_campaign_arn = create_campaign_response['campaignArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(campaignArn = sims_campaign_arn)\n",
    "    status = describe_campaign_response['campaign']['status']\n",
    "    print('Campaign: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you will create the campaign for the SIMS based Solution where you used the HPO optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_campaign_response = personalize.create_campaign(name = 'ret310-sims-hpo-campaign',\n",
    "                                                       solutionVersionArn = sims_hpo_version_arn,\n",
    "                                                       minProvisionedTPS = 1)\n",
    "\n",
    "sims_hpo_campaign_arn = create_campaign_response['campaignArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(campaignArn = sims_hpo_campaign_arn)\n",
    "    status = describe_campaign_response['campaign']['status']\n",
    "    print('Campaign: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you will create the campaign for the personalized ranking based solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_campaign_response = personalize.create_campaign(name = 'ret310-ranking-campaign',\n",
    "                                                       solutionVersionArn = ranking_version_arn,\n",
    "                                                       minProvisionedTPS = 1)\n",
    "\n",
    "ranking_campaign_arn = create_campaign_response['campaignArn']\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(campaignArn = ranking_campaign_arn)\n",
    "    status = describe_campaign_response['campaign']['status']\n",
    "    print('Campaign: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 7 - Testing the deployed Campaigns using the Python SDK<a class=\"anchor\" id=\"seventh-section\"></a>\n",
    "\n",
    "As last step on this exercise we will simualte inferences against the Amazon Personalize Campaigns endpoints.\n",
    "\n",
    "First we will use the get_recommendations() API against the SIMS based Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "response = personalize_runtime.get_recommendations(campaignArn = sims_hpo_campaign_arn,\n",
    "                                                   itemId = 'cef67bcfe19066a932b7673e239eb23d',\n",
    "                                                   numResults = 10)\n",
    "\n",
    "for item in response['itemList']:\n",
    "    print('item:', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will use the Personalize Ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "list_of_products = ['99a4788cb24856965c36a24e339b6058', 'aca2eb7d00ea1a7b8ebd4e68314663af',\n",
    "                    '422879e10f46682990de24d770e7f83d', 'd1c427060a0f73f6b889a5c7c61f2ac4',\n",
    "                    '53b36df67ebb7c41585e8d54d6772e08', '389d119b48cf3043d311335e499d9c6b',\n",
    "                    '368c6c730842d78016ad823897a372db', '53759a2ecddad2bb87a079a1f1519f73',\n",
    "                    '154e7e31ebfa092203795c972e5804a6', '2b4609f8948be18874494203496bc318']\n",
    "\n",
    "print('initial products list:\\n', list_of_products, '\\n')\n",
    "\n",
    "response = personalize_runtime.get_personalized_ranking(campaignArn = ranking_campaign_arn,\n",
    "                                                userId = '18955e83d337fd6b2def6b18a428ac77',\n",
    "                                                inputList = list_of_products)\n",
    "\n",
    "print('ranked products list:\\n')\n",
    "\n",
    "for item in response['personalizedRanking']:\n",
    "    print (item['itemId'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 8 - Clean Up steps<a class=\"anchor\" id=\"eighth-section\"></a>\n",
    "\n",
    "After running all steps mentioned here, it is time to clean up your account. This will remove all objects/services created to make this exercise possible. It includes IAM and Personalize resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all the deployed Campaigns - the output of this cell must be []:\n",
    "\n",
    "personalize.delete_campaign(campaignArn=sims_campaign_arn)\n",
    "personalize.delete_campaign(campaignArn=sims_hpo_campaign_arn)\n",
    "personalize.delete_campaign(campaignArn=ranking_campaign_arn)\n",
    "time.sleep(300)\n",
    "\n",
    "print(personalize.list_campaigns(solutionArn=sims_version_arn)['campaigns'])\n",
    "print(personalize.list_campaigns(solutionArn=sims_hpo_version_arn)['campaigns'])\n",
    "print(personalize.list_campaigns(solutionArn=ranking_version_arn)['campaigns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all the deployed Solutions versions - the output of this cell must be []:\n",
    "\n",
    "personalize.delete_solution(solutionArn=popularity_solution_arn)\n",
    "personalize.delete_solution(solutionArn=sims_solution_arn)\n",
    "personalize.delete_solution(solutionArn=sims_hpo_solution_arn)\n",
    "personalize.delete_solution(solutionArn=ranking_solution_arn)\n",
    "time.sleep(300)\n",
    "\n",
    "personalize.list_solutions(datasetGroupArn=dataset_group_arn)['solutions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all datasets - the output of this cell must be []:\n",
    "\n",
    "personalize.delete_dataset(datasetArn=users_dataset_arn)\n",
    "personalize.delete_dataset(datasetArn=products_dataset_arn)\n",
    "personalize.delete_dataset(datasetArn=interactions_dataset_arn)\n",
    "time.sleep(300)\n",
    "\n",
    "datasets = personalize.list_datasets(datasetGroupArn=dataset_group_arn)['datasets']\n",
    "if datasets:\n",
    "    for dataset in datasets:\n",
    "        print(dataset['name'])\n",
    "else:\n",
    "    print([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the dataset group - the output of this cell must be []:\n",
    "\n",
    "personalize.delete_dataset_group(datasetGroupArn=dataset_group_arn)\n",
    "\n",
    "dgs = personalize.list_dataset_groups()['datasetGroups']\n",
    "available = []\n",
    "for dg in dgs:\n",
    "    if dg['name'] == dataset_group_arn:\n",
    "        available.append(1)\n",
    "if not available:\n",
    "    print(available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the data schemas - the output of this cell must be []:\n",
    "\n",
    "personalize.delete_schema(schemaArn='arn:aws:personalize:us-west-2:230440465708:schema/ret310-users-schema')\n",
    "personalize.delete_schema(schemaArn='arn:aws:personalize:us-west-2:230440465708:schema/ret310-products-schema')\n",
    "personalize.delete_schema(schemaArn='arn:aws:personalize:us-west-2:230440465708:schema/ret310-interactions-schema')\n",
    "\n",
    "ret310_schemas = ['ret310-users-schema', 'ret310-products-schema', 'ret310-interactions-schema']\n",
    "\n",
    "schemas = personalize.list_schemas()['schemas']\n",
    "available = []\n",
    "for schema in schemas:\n",
    "    if schema['name'] in ret310_schemas:\n",
    "        available.append(1)\n",
    "if not available:\n",
    "    print(available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting all IAM objects\n",
    "\n",
    "iam.detach_role_policy(RoleName=role_name, PolicyArn=policyArn)\n",
    "time.sleep(10)\n",
    "iam.delete_policy(PolicyArn=policyArn)\n",
    "time.sleep(10)\n",
    "iam.delete_role(RoleName=role_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
